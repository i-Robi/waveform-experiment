<!DOCTYPE html>
<html>
<head>
  <title>Loading and playing a sound with the Web Audio API</title>
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js"></script>
  <script src="d3.v3.min.js"></script>
  <style>
  * {
    font-family: sans-serif;
  }

  body{
    background-color: black;
    text-align: center;
  }

  path {
    stroke: white;
    stroke-width: 2;
    fill: none;
  }

  #container {
    text-align: center;
    width: 500px;
    margin: auto;
  }
  #fft {
    background: black;
  }
  svg{background-color: black;}
  
  </style>

</head>

<body>
  <canvas height="0" width="0" id="fft"></canvas>
  <audio id="audio" src="music.mp3" style="text-align: center;" preload controls></audio>

  <div id="graph" class="aGraph" style="text-align: center;"></div>


  <script type="text/javascript">

  // requestAnim shim layer by Paul Irish
  window.requestAnimFrame = (function(){
    return  window.requestAnimationFrame       || 
    window.webkitRequestAnimationFrame || 
    window.mozRequestAnimationFrame    || 
    window.oRequestAnimationFrame      || 
    window.msRequestAnimationFrame     || 
    function(/* function */ callback, /* DOMElement */ element){
      window.setTimeout(callback, 1000 / 60);
    };
  })();
  

  </script>

  <script type="text/javascript">




// The audio element
audioElement = document.getElementById('audio');


var fillWithZeros = function(array, l) {
  for (var i = 0; i < l; i++) {
    arrayInit[i] = 0;
  }
};

var boxcarApproximation = function(x) {
  return 1 / ( 1 + Math.exp( -32 * ( x + 4/12 ) ) ) * ( 1 - 1/( 1 + Math.exp( -32 * ( x - 4/12 ) ) ) );
};

var gaussianEnvelope = function(array) {
  var l = array.length;

  var result = new Array();

  for (var i = 0; i < l; i++) {
    // result[i] = array[i]*Math.exp(-Math.pow(i-l/2, 2)/(2*l));
    result[i] = array[i]*boxcarApproximation((i-l/2)/l)/3;
  }

  return result;
};

var yShift = function(array, alpha) {
  var l = array.length;
  var result = new Array();

  for (var i = 0; i < l; i++) {
    // result[i] = array[i]*Math.exp(-Math.pow(i-l/2, 2)/(2*l));
    result[i] = array[i] + alpha*10;
  }

  return result
}




var sampling = 512;
var arrayInit = new Array();
fillWithZeros(arrayInit, sampling);
var arrayInitial = [arrayInit.slice(0, Math.floor(arrayInit.length/2)), arrayInit.slice(Math.floor(arrayInit.length/2), 2*Math.floor(arrayInit.length/2))];

console.log(arrayInitial);

var w = 200,
h = 100,
margin = 20,
y = d3.scale.linear().domain([0, h]).range([0 + margin, h - margin]),
x = d3.scale.linear().domain([0, arrayInit.length/4]).range([0 + margin, w - margin]);


var line = d3.svg.line()
.interpolate("basis") 
.x(function(d,i) { return x(i); })
.y(function(d) { return -1 * y(d); })


var graph = d3.select("#graph").append("svg:svg")
.attr("width", w)
.attr("height", h)
.append("svg:g")
.attr("transform", "translate(0, " + h + ")");


console.log(arrayInit);

    // graph.append("svg:path").attr("d", line(arrayInit));

graph.selectAll('path.line')
  .data([
    gaussianEnvelope(arrayInit.slice(0, arrayInit.length/4)),
    gaussianEnvelope(arrayInit.slice(arrayInit.length/4, 2*arrayInit.length/4)),
    gaussianEnvelope(arrayInit.slice(2*arrayInit.length/4, 3*arrayInit.length/4))
  ])
  .enter()
  .append("svg:path")
  .attr("d", line)
  .classed("line", true);


// The canvas, its context and fillstyle
canvas = document.getElementById('fft');
ctx = canvas.getContext('2d');
ctx.fillStyle = "white";

// Create new Audio Context and an audio analyzer
audioContext = new webkitAudioContext();
analyser = audioContext.createAnalyser();
analyser.fftSize = sampling*2;
analyser.smoothingTimeConstant = 0.8;

// Canvas' height and width
CANVAS_HEIGHT = canvas.height;
CANVAS_WIDTH = canvas.width;
// We'll need the offset later
OFFSET = 100;
// Spacing between the individual bars
SPACING = 10;
// Initialize and start drawing
// when the audio starts playing
window.onload = init;
audioElement.addEventListener('play', draw);

function init() {
  // Take input from audioElement
  source = audioContext.createMediaElementSource(audioElement);
  // Connect the stream to an analyzer
  source.connect(analyser);
  // Connect the analyzer to the speakers
  analyser.connect(audioContext.destination);
  // Start the animation
  draw();
}

function draw() {
  // See http://paulirish.com/2011/requestanimationframe-for-smart-animating/
  requestAnimFrame(draw, canvas);
  // New typed array for the raw frequency data
  freqData = new Uint8Array(analyser.frequencyBinCount);
  // Put the raw frequency into the newly created array
  // analyser.getByteTimeDomainData(freqData);
  analyser.getByteFrequencyData(freqData);
  // // Clear the canvas
  // ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
  // // This loop draws all the bars
  // for (var i = 0; i < freqData.length - OFFSET; i++) {
  //   // Work out the hight of the current bar
  //   // by getting the current frequency
  //   var magnitude = freqData[i + OFFSET];
  //   // Draw a bar from the bottom up (cause for the "-magnitude")
  //   ctx.fillRect(i * SPACING, CANVAS_HEIGHT, SPACING / 2, -magnitude);
  // };

  var frequencyData = [freqData, gaussianEnvelope(freqData)];


  graph.selectAll("path.line")
    .data([
      yShift(gaussianEnvelope(freqData.subarray(0, freqData.length/4)), 2),
      yShift(gaussianEnvelope(freqData.subarray(freqData.length/4, 2*freqData.length/4)), 1),
      yShift(gaussianEnvelope(freqData.subarray(2*freqData.length/4, 3*freqData.length/4)), 0)
    ]) // set the new data
   .transition()
   .duration(30)
   .attr("d", line);
   // .ease("elastic"); // apply the new data values


 }




</script>

</body>
</html>